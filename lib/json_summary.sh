# lib/json_summary.sh (POSIX-friendly)
# Build a machine-readable JSON summary from artifacts/
# Avoid bash-only features so it can be sourced by /bin/sh as well.

num_or_zero() {
  case "$1" in
    ''|*[!0-9]*) printf '0' ;;
    *) printf '%s' "$1" ;;
  esac
}

now_utc() { date -u +%Y-%m-%dT%H:%M:%SZ; }

# Extract METRIC:key=value pairs from a stdout.log and emit a JSON object
collect_metrics_from_stdout() {
  file="$1"
  if [ ! -f "$file" ]; then
    printf '{}'
    return 0
  fi
  # Build a simple JSON object with jq; if jq missing, return {}
  if command -v jq >/dev/null 2>&1; then
    awk -F'METRIC:' '/^METRIC:/{print $2}' "$file"     | awk -F'=' '
      {
        key=$1; sub(/^[ \t]+/,"",key); sub(/[ \t]+$/,"",key);
        $1=""; val=substr($0,2);
        gsub(/^[ \t]+|[ \t]+$/, "", val);
        printf("{\"k\":\"%s\",\"v\":\"%s\"}\n", key, val);
      }'     | jq -cs '
        reduce .[] as $p ({}; .[$p.k] = $p.v )
      '
  else
    printf '{}'
  fi
}

# Write the JSON summary file
# Args: out results_log skip_log resource_group location series_filter max_parallel
write_summary_json() {
  out="$1"; results_log="$2"; skip_log="$3"; rg="$4"; loc="$5"; sf="$6"; mp="$7"

  GOOD=$(grep -c '^GOOD|' "$results_log" 2>/dev/null || true)
  BAD=$(grep -c '^BAD|' "$results_log" 2>/dev/null || true)
  SKIP=$(grep -c '^SKIP|' "$skip_log"    2>/dev/null || true)

  if ! command -v jq >/dev/null 2>&1; then
    # Minimal fallback JSON
    mkdir -p "$(dirname "$out")"
    {
      printf '{'
      printf '"_comments":"fallback JSON (jq not found)",'
      printf '"run":{"timestamp":"%s","resource_group":"%s","location":"%s","series_filter":"%s","max_parallel":"%s"},' "$(now_utc)" "$rg" "$loc" "$sf" "$mp"
      printf '"totals":{"GOOD":%s,"BAD":%s,"SKIP":%s},' "$(num_or_zero "$GOOD")" "$(num_or_zero "$BAD")" "$(num_or_zero "$SKIP")"
      printf '"results":[],"skips":[],"metrics":[],"vm_rollup":{}'
      printf '}
'
    } > "$out"
    return 0
  fi

  jq -n     --arg ts "$(now_utc)"     --arg rg "$rg" --arg loc "$loc" --arg sf "$sf" --arg mp "$mp"     --argjson good "$(num_or_zero "$GOOD")"     --argjson bad  "$(num_or_zero "$BAD")"     --argjson skip "$(num_or_zero "$SKIP")"     '{
      _comments: "Test summary generated by json_summary.sh",
      run: { timestamp: $ts, resource_group: $rg, location: $loc, series_filter: $sf, max_parallel: $mp },
      totals: { GOOD: $good, BAD: $bad, SKIP: $skip },
      results: [], skips: [], metrics: [], vm_rollup: {}
    }' > "$out"

  # Append results
  if [ -f "$results_log" ]; then
    tmp_res="$(mktemp)"
    while IFS='|' read -r status vm test series type size offer sku _rest; do
      [ -z "$status" ] && continue
      case "$status" in
        GOOD|BAD)
          jq -c --arg s "$status" --arg vm "$vm" --arg t "$test"                 --arg se "$series" --arg ty "$type" --arg si "$size"                 --arg of "$offer"  --arg sk "$sku"                 '.results += [{status:$s, vm:$vm, test:$t, series:$se, type:$ty, size:$si, offer:$of, sku:$sk}]'                 "$out" > "$tmp_res" && mv "$tmp_res" "$out"
        ;;
      esac
    done < "$results_log"
  fi

  # Append skips
  if [ -f "$skip_log" ]; then
    tmp_sk="$(mktemp)"
    # Expect: SKIP|<vm>|<test>|<series>|<type>|<size>|code=<CODE>|reason=<TEXT>
    while IFS='|' read -r status vm test series type size rest; do
      [ "$status" != "SKIP" ] && continue
      code="$(printf '%s' "$rest" | awk -F'code=' '{print $2}' | awk -F'|' '{print $1}')"
      reason="$(printf '%s' "$rest" | awk -F'reason=' '{print $2}' )"
      critical="false"
      case "$code" in
        RUN:SSH|RUN:REBOOT_SSH|RUN:SSH_LOST) critical="true" ;;
      esac
      jq -c --arg vm "$vm" --arg t "$test"             --arg se "$series" --arg ty "$type" --arg si "$size"             --arg code "$code" --arg reason "$reason"             --argjson critical "$critical"             '.skips += [{vm:$vm, test:$t, series:$se, type:$ty, size:$si, code:$code, reason:$reason, critical:$critical}]'             "$out" > "$tmp_sk" && mv "$tmp_sk" "$out"
    done < "$skip_log"
  fi

  # Scan artifacts for per-test metrics and VM rollups
  if [ -d artifacts ]; then
    metrics_array='[]'
    vm_rollup='{}'
    # list VMs
    find artifacts -maxdepth 1 -mindepth 1 -type d -printf "%f
" | sort | while IFS= read -r vm; do
      merged='{}'
      # list tests for VM
      find "artifacts/$vm" -maxdepth 1 -mindepth 1 -type d -printf "%f
" | sort | while IFS= read -r t; do
        f="artifacts/$vm/$t/stdout.log"
        m="$(collect_metrics_from_stdout "$f")"
        # append to metrics_array
        metrics_array="$(jq -cn --arg vm "$vm" --arg t "$t" --argjson m "$m" --argjson arr "$metrics_array" '$arr + [{vm:$vm, test:$t, metrics:$m}]')"
        merged="$(jq -cn --argjson A "$merged" --argjson B "$m" '$A + $B')"
      done
      vm_rollup="$(jq -cn --arg vm "$vm" --argjson R "$vm_rollup" --argjson M "$merged" '$R + {($vm): $M}')"
    done

    tmp="$(mktemp)";  jq --argjson arr "$metrics_array" '.metrics = $arr' "$out" > "$tmp" && mv "$tmp" "$out"
    tmp="$(mktemp)";  jq --argjson vr  "$vm_rollup"     '.vm_rollup = $vr' "$out" > "$tmp" && mv "$tmp" "$out"
  fi
}